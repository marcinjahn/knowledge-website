(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{492:function(e,t,a){e.exports=a.p+"assets/img/jaeger-example.75276063.png"},517:function(e,t,a){"use strict";a.r(t);var s=a(22),o=function(e){e.options.__data__block__={mermaid_382ee168:"flowchart LR\n    app1(App 1 + SDK) --\x3e collector\n    app2(App 2 + SDK) --\x3e collector\n\n    collector(Collector) --\x3e db[(Database)]\n\n    db --\x3e ui(UI)\n",mermaid_382ee187:"flowchart LR\n    app1(App + SDK) --\x3e agent(Agent)\n\n    agent --\x3e collector\n\n    collector(Collector) --\x3e db[(Database)]\n",mermaid_382ee1a9:"flowchart LR\n    i(Instrumentation) --\x3e p(Processor) --\x3e e(Exporter)\n",mermaid_64a56f2c:"flowchart LR\n    r(Receiver) --\x3e p(Processor) --\x3e e(Exporter)\n"}},n=Object(s.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"tracing"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tracing"}},[e._v("#")]),e._v(" Tracing")]),e._v(" "),s("p",[e._v("Tracing is one of the pillards of "),s("strong",[e._v("Observability")]),e._v(". It is analogous to stack\ntrace of a program, but in the distributed world of (micro)services.")]),e._v(" "),s("p",[e._v("First, it started as seperate efforts of various entites, nowadays it is\nstandardized under the "),s("a",{attrs:{href:"https://opentelemetry.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Open Telemetry"),s("OutboundLink")],1),e._v(" initiative (a\npart of "),s("a",{attrs:{href:"https://www.cncf.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CNCF"),s("OutboundLink")],1),e._v(").")]),e._v(" "),s("p",[e._v("A "),s("strong",[e._v("trace")]),e._v(" is a collection of "),s("strong",[e._v("spans")]),e._v(' - time-bound operations that are part\nof some scenario. Most often these are network calls, but they can also\nrepresent other things. We could  actually represent a "traditional" call stack\nof a single process with spans of a trace. Although possible, it\'s not the\nrecommended approach. It is alright though to include the most important parts\nof a single process (especially the ones that take majority of time of a trace)\nin a trace.')]),e._v(" "),s("p",[e._v("Here's an illustration that represents tracing, found in the "),s("a",{attrs:{href:"https://www.jaegertracing.io/docs/1.41/architecture/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Jaeger\nDocs"),s("OutboundLink")],1)]),e._v(" "),s("p",[s("img",{attrs:{src:a(492),alt:"Jaeger Example"}})]),e._v(" "),s("h2",{attrs:{id:"architecture"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#architecture"}},[e._v("#")]),e._v(" Architecture")]),e._v(" "),s("p",[e._v("Most often, the general tracing setup looks like this:")]),e._v(" "),s("Mermaid",{attrs:{id:"mermaid_382ee168",graph:e.$dataBlock.mermaid_382ee168}}),s("p",[e._v("The "),s("em",[e._v("SDK")]),e._v(" and "),s("em",[e._v("Collector")]),e._v(" are a part of OpenTelemetry. The UI needs to be\nsomething that conforms to the OpenTelemetry standard, e.g.\n"),s("a",{attrs:{href:"https://www.jaegertracing.io",target:"_blank",rel:"noopener noreferrer"}},[e._v("Jaeger"),s("OutboundLink")],1),e._v(". The choice of teh database is dictated\nby both the Collector and UI, since both theses entities will access the\ndatabase.")]),e._v(" "),s("p",[e._v("The architecture could differ, some new actors could be added (like agents), or\nremoved (e.g., Jaeger could be run with in-memory database).")]),e._v(" "),s("p",[e._v("Here's how it could look like with Agent added:")]),e._v(" "),s("Mermaid",{attrs:{id:"mermaid_382ee187",graph:e.$dataBlock.mermaid_382ee187}}),s("p",[e._v("The purpose of having an Agent is to relax the burden of network communication\nbetween the App and the Collector. The communication with the Collector could be\nslow. The communication between the App and the Agent should be fast (Agent\ncould be a side-car of our App).")]),e._v(" "),s("p",[e._v("Other than that, the Agent is actually the same app as Collector. It has a bunch\nof configuration that could be useful for us (explained down below).")]),e._v(" "),s("h3",{attrs:{id:"sdk"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sdk"}},[e._v("#")]),e._v(" SDK")]),e._v(" "),s("p",[e._v("Looking at a single app, the SDK works in a pipeline, like this:")]),e._v(" "),s("Mermaid",{attrs:{id:"mermaid_382ee1a9",graph:e.$dataBlock.mermaid_382ee1a9}}),s("h4",{attrs:{id:"instrumentation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#instrumentation"}},[e._v("#")]),e._v(" Instrumentation")]),e._v(" "),s("p",[e._v("Instrumentation is the origin of every span. We can create spans manually, or\nautomatically via auto-instrumentation. Auto-instrumentation is specific to\nvarious protocols/frameworks. E.g., we could install auto-instrumentation for\nExpress or Nest.js, and it will automatically create spans for every incoming\nrequest. Many frameworks have some accompanying auto-instrumentation (often\nvarious versions for the same framework).")]),e._v(" "),s("p",[e._v("Spans may have some additional metadata attached. These are "),s("strong",[e._v("Resources")]),e._v(". We\ncan add some data to every span, enriching them. Examples include:")]),e._v(" "),s("ul",[s("li",[e._v("git commit ID of the running process")]),e._v(" "),s("li",[e._v("container ID of the running process")])]),e._v(" "),s("p",[e._v("There are also additional apckages called "),s("strong",[e._v("Detectors")]),e._v(". They are able to\nautomatically attach some environment-specific data to our Resources. Examples\ncould include Azure Detector or AWS Detector. These would automatically include\nsome cloud-specific data to our spans. Similarly, git Detector would attach\ncommit ID (if "),s("code",[e._v(".git")]),e._v(" directory is part of the deployment). A detector could also\ndiscover the name of our service (e.g., based on "),s("code",[e._v("package.json")]),e._v(").")]),e._v(" "),s("p",[e._v("All the setup of tracing is wrapped in a provied - e.g. "),s("code",[e._v("NodeProvider")]),e._v(" for\nNode.js apps.")]),e._v(" "),s("h5",{attrs:{id:"custom-intrumentation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#custom-intrumentation"}},[e._v("#")]),e._v(" Custom Intrumentation")]),e._v(" "),s("p",[e._v('The SDK allows us to implement custom intrumentations. That may come useful when\nsome framework or library does not have any available instrumentations.\nAuto-intrumentation helps in keeping the code clean of tracing logic. Manual\ninstrumentation on the other hand, "pollutes" the code with non-business logic.')]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),s("p",[e._v("Sometimes, manual instrumentation is the right choice! It's only the cases that\nare non-seldom and well-defined that benefit the most from auto-instrumentation.")]),e._v(" "),s("p",[e._v("It's often best to start with manual instrumentation and create\nauto-instrumentation based on it later on.")])]),e._v(" "),s("h4",{attrs:{id:"processors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#processors"}},[e._v("#")]),e._v(" Processors")]),e._v(" "),s("p",[e._v("Processors sit between the instrumentation and exporters. Most often, they are\nused for batching. Out-of-the-box, the following processors are available:")]),e._v(" "),s("ul",[s("li",[e._v("SimpleProcessor - just relays every single span to the Exporter")]),e._v(" "),s("li",[e._v("BatchProcessor - batches spans and relays these batches to the Exporter")]),e._v(" "),s("li",[e._v("NoOpProcessor - drops every span, nothing will be sent")]),e._v(" "),s("li",[e._v("MultipleProcessor - allows to compose multiple processors in a single pipeline")])]),e._v(" "),s("h4",{attrs:{id:"propagators"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#propagators"}},[e._v("#")]),e._v(" Propagators")]),e._v(" "),s("p",[e._v("In some cases, it is difficult to attach tracing metadata in the messaging with\nother services. WebSockets could be an example of such messaging. WebSockets do\nnot support any way of sending metadata, like headers in HTTP. Because of that,\ndata like "),s("code",[e._v("traceId")]),e._v(" needs to be sent as part of application message. The SDK\ncomes with a propagator that can both inject and extract that metadata from the\nmessages. Both the sender and the receiver need to be aware of this metadat\nbeing there.")]),e._v(" "),s("p",[e._v("Another example could be Redis - it also does not support metadata.")]),e._v(" "),s("h2",{attrs:{id:"traces"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#traces"}},[e._v("#")]),e._v(" Traces")]),e._v(" "),s("p",[e._v("Traces are composed of spans. Spans are composed of:")]),e._v(" "),s("ul",[s("li",[e._v("timestamps (start and end)")]),e._v(" "),s("li",[e._v("origin service")]),e._v(" "),s("li",[e._v("events - things that happened during the span, but do not deserve their own\nseparate span. Potentially, that could be due to the fact that they do not\nhave start-end timestamps.")]),e._v(" "),s("li",[e._v("attributes - key-value pairs of meta-data (similar to Resources, but we can\nattach them ad-hoc, isntead of predefining for all spans)")]),e._v(" "),s("li",[e._v("errors - if an exception occurs during the span, the error message could be added.")]),e._v(" "),s("li",[e._v("traceId - each span belongs to some trace.")])]),e._v(" "),s("p",[e._v("An important concept is how traceId is being shared among services. There always\nis some root service where the journey starts. That service generates the\ntraceId. Any call to other services will include that traceId. This way, when\nthese downstream services record their spans, they will attach the traceId that\nthey received.")]),e._v(" "),s("p",[e._v('Traces are being sent by all the services to the collector (could be via Agents,\nbut it doens\'t matter in this context). Interestingly, a root service (or any\nother service in the chain) may decide not to trace (e.g. due to sampling\nconfiguration). That decision may be transmitted to the "child" services. If\nthese services are properly configured, they will respect the upstream decision,\nand will not trace the traffic.')]),e._v(" "),s("h2",{attrs:{id:"collector"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#collector"}},[e._v("#")]),e._v(" Collector")]),e._v(" "),s("p",[e._v("The collector works very similarly to the SDK in an app. It has a pipeline:")]),e._v(" "),s("Mermaid",{attrs:{id:"mermaid_64a56f2c",graph:e.$dataBlock.mermaid_64a56f2c}}),s("p",[e._v("There could be many receivers, processors, and exporters. Instead of\ninitializing the pipeline in code (like we do with the SDK), we do it in YAML.")]),e._v(" "),s("p",[e._v("Processors include things like Sampling.")]),e._v(" "),s("h3",{attrs:{id:"sampling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sampling"}},[e._v("#")]),e._v(" Sampling")]),e._v(" "),s("p",[e._v("One of the most important things to configure in a Collector is "),s("strong",[e._v("Sampling")]),e._v(". In\nbigger systems, the amount of traces that we collect could have significant\nimpact on the costs and performance.")]),e._v(" "),s("p",[e._v("In general, the following samping strategies should be applied:")]),e._v(" "),s("ul",[s("li",[s("strong",[e._v("100%")]),e._v(" sampling - when we don't have a lot of traffic in the systems, it might\nbe alright to just log everything")]),e._v(" "),s("li",[s("strong",[e._v("20-50%")]),e._v(" - debugging issues - this amount of traces should be enough to debug\nsome system-wide issue")]),e._v(" "),s("li",[s("strong",[e._v("5-10%")]),e._v(" - typical setup - it should be enough for general monitoring of the\nsystem. If something fails, we'll record 10% of failures")]),e._v(" "),s("li",[s("strong",[e._v("5%")]),e._v(" - understanding the system architecture")])]),e._v(" "),s("p",[e._v("The sampling may be configured with more details, like logging 10% of traces\nuncless there's an error - then, we'd always log it.")]),e._v(" "),s("p",[e._v("Sampling can be done on two levels:")]),e._v(" "),s("ul",[s("li",[e._v("app (SDK) - "),s("strong",[e._v("head-sampling")]),e._v(" - apps decide what to send")]),e._v(" "),s("li",[e._v("collector - "),s("strong",[e._v("tail-sampling")]),e._v(" - apps send everything")])]),e._v(" "),s("p",[e._v("Some mix of the two could also be utilized.")]),e._v(" "),s("p",[e._v("The difference between the two is about the point in time when the decision to\nsample is being made.")]),e._v(" "),s("h4",{attrs:{id:"head-sampling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#head-sampling"}},[e._v("#")]),e._v(" Head-Sampling")]),e._v(" "),s("p",[e._v("In head-sampling, when the root service decides not to trace some request, it\nwill ask downstream services not to trace as well. If, during that journey, some\nerror occurs, trafific will not be traced (unlesss some child service is\nconfigured otherwise, but it will not help us with missing spans from the parent\nthat did not want to trace).")]),e._v(" "),s("p",[e._v("Service that makes the sampling decision makes it "),s("em",[e._v("before")]),e._v(" a potential issue\noccurs. It's non-ideal.")]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("0%")]),e._v(" "),s("p",[e._v("In tail-sampling, even with 0% sampling configured, services will still transfer\ntracing header between each other - that's needed for downstream services\nto know that they should not send traces to the collector!")])]),e._v(" "),s("h3",{attrs:{id:"tail-sampling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tail-sampling"}},[e._v("#")]),e._v(" Tail-Sampling")]),e._v(" "),s("p",[e._v("In tail-sampling, the collector has access to the whole trace and may decide\nwhether it wants to store it or not. The decision can be made based on various\nfactors:")]),e._v(" "),s("ul",[s("li",[e._v("span(s) latency")]),e._v(" "),s("li",[e._v("some attribute values (e.g. HTTP status codes)")]),e._v(" "),s("li",[e._v("span(s) status codes (since traces can have errors attached)")]),e._v(" "),s("li",[e._v("rate limiting (e.g. max 50/s)")]),e._v(" "),s("li",[e._v("probabilistic (e.g. 50%)")])]),e._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[e._v("Decision time")]),e._v(" "),s("p",[e._v("Spans arrive at the collector asynchronously. The collector cannot really tell\nif at some point in time all the spans composing a given trace were already\ncollected. This is why one of the parameters affecting sampling is "),s("em",[e._v("decision\ntime")]),e._v(". This is the timespan that the collector should allow for incoming spans\nto come in (starting from the first one that came in) until the sampling\ndecision is made.\nBefore making the decision to sample, spans are stored in-memory.")])]),e._v(" "),s("div",{staticClass:"custom-block warning"},[s("p",{staticClass:"custom-block-title"},[e._v("Load Balancing")]),e._v(" "),s("p",[e._v("In bigger systems, with multiple collector replicas, it's important to configure\ntrace affinity, so that one collector wil receive all the spans belonging to a\nsingle trace. That way, sampling decisions may be better informed.")])]),e._v(" "),s("hr"),e._v(" "),s("p",[e._v("Head vs tail sampling:")]),e._v(" "),s("ul",[s("li",[e._v("when we only want to log errors - Tail")]),e._v(" "),s("li",[e._v("when we want to log only traces with latency problems - Tail")]),e._v(" "),s("li",[e._v("when we want to log only specific routes - Head")])]),e._v(" "),s("h2",{attrs:{id:"tips"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tips"}},[e._v("#")]),e._v(" Tips")]),e._v(" "),s("ul",[s("li",[e._v("In Node.js, tracing needs to be enabled before even importing any other\nnon-tracing related dependencies!")])])],1)}),[],!1,null,null,null);"function"==typeof o&&o(n);t.default=n.exports}}]);